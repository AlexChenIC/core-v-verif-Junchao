# éªŒè¯è®¡åˆ’åˆ†æå·¥å…·é›†

æœ¬ç›®å½•åŒ…å«åŸºäºCV32E40Pé¡¹ç›®å¼€å‘çš„å®ç”¨åˆ†æå·¥å…·ï¼Œç”¨äºéªŒè¯è®¡åˆ’çš„ç”Ÿæˆã€åˆ†æã€éªŒè¯å’Œä¼˜åŒ–ã€‚

## ğŸ› ï¸ å·¥å…·åˆ†ç±»

### 1. æ ¸å¿ƒåˆ†æå·¥å…·

| å·¥å…·åç§° | åŠŸèƒ½æè¿° | è¾“å…¥æ ¼å¼ | è¾“å‡ºæ ¼å¼ | ä½¿ç”¨é¢‘ç‡ |
|----------|----------|----------|----------|----------|
| `excel_analyzer.py` | ExceléªŒè¯è®¡åˆ’æ·±åº¦åˆ†æ | .xlsx | JSON/HTML | æ¯æ¬¡æ›´æ–° |
| `completeness_checker.py` | å®Œæ•´æ€§å’Œè¦†ç›–åº¦æ£€æŸ¥ | .xlsx + éœ€æ±‚DB | æŠ¥å‘Š | æ¯å‘¨ |
| `quality_scorer.py` | è´¨é‡è¯„åˆ†å’Œæ”¹è¿›å»ºè®® | .xlsx | å¾—åˆ†æŠ¥å‘Š | æ¯æ¬¡Review |
| `consistency_validator.py` | ä¸€è‡´æ€§éªŒè¯å·¥å…· | .xlsx | éªŒè¯æŠ¥å‘Š | æäº¤å‰ |

### 2. æ•°æ®å¤„ç†å·¥å…·

| å·¥å…·åç§° | åŠŸèƒ½æè¿° | é€‚ç”¨åœºæ™¯ |
|----------|----------|----------|
| `xlsx_to_json.py` | Excelè½¬JSONæ•°æ®æå– | æ•°æ®åˆ†æ |
| `vplan_merger.py` | å¤šä¸ªéªŒè¯è®¡åˆ’åˆå¹¶ | é¡¹ç›®æ•´åˆ |
| `template_generator.py` | åŸºäºåˆ†æç»“æœç”Ÿæˆæ¨¡æ¿ | æ–°é¡¹ç›®å¯åŠ¨ |
| `coverage_calculator.py` | è¦†ç›–ç‡ç»Ÿè®¡è®¡ç®— | è¿›åº¦è¿½è¸ª |

### 3. å¯è§†åŒ–å·¥å…·

| å·¥å…·åç§° | åŠŸèƒ½æè¿° | è¾“å‡ºç±»å‹ |
|----------|----------|----------|
| `dashboard_generator.py` | äº¤äº’å¼ä»ªè¡¨æ¿ç”Ÿæˆ | HTML/JS |
| `progress_visualizer.py` | è¿›åº¦å¯è§†åŒ–å›¾è¡¨ | SVG/PNG |
| `dependency_mapper.py` | ä¾èµ–å…³ç³»å›¾ç”Ÿæˆ | GraphViz |
| `risk_heatmap.py` | é£é™©çƒ­åŠ›å›¾ç”Ÿæˆ | HTML/SVG |

### 4. é›†æˆå’Œè‡ªåŠ¨åŒ–

| å·¥å…·åç§° | åŠŸèƒ½æè¿° | é›†æˆæ–¹å¼ |
|----------|----------|----------|
| `ci_integration.py` | CI/CDé›†æˆè„šæœ¬ | GitHub Actions |
| `slack_reporter.py` | Slackè‡ªåŠ¨æŠ¥å‘Š | Webhook |
| `email_notifier.py` | é‚®ä»¶é€šçŸ¥ç³»ç»Ÿ | SMTP |
| `jira_sync.py` | JIRAåŒæ­¥å·¥å…· | REST API |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè®¾ç½®

```bash
# å®‰è£…Pythonä¾èµ–
pip install -r tools/requirements.txt

# å®‰è£…é¢å¤–å·¥å…·ï¼ˆå¯é€‰ï¼‰
# GraphViz for dependency visualization
sudo apt-get install graphviz

# è®¾ç½®ç¯å¢ƒå˜é‡
export PYTHONPATH="${PYTHONPATH}:$(pwd)/tools"
```

### åŸºç¡€ä½¿ç”¨ç¤ºä¾‹

```bash
# åˆ†æå•ä¸ªExceléªŒè¯è®¡åˆ’
python3 tools/excel_analyzer.py \
  --input verification_plans/CV32E40P_OBI_VerifPlan.xlsx \
  --output analysis_report.html \
  --format html

# æ£€æŸ¥å¤šä¸ªéªŒè¯è®¡åˆ’çš„å®Œæ•´æ€§
python3 tools/completeness_checker.py \
  --plans-dir verification_plans/ \
  --requirements requirements_db.json \
  --output completeness_report.json

# ç”Ÿæˆé¡¹ç›®ä»ªè¡¨æ¿
python3 tools/dashboard_generator.py \
  --data-dir verification_plans/ \
  --output dashboard.html \
  --template cv32e40p
```

## ğŸ“Š æ ¸å¿ƒåˆ†æå·¥å…·è¯¦è§£

### 1. ExceléªŒè¯è®¡åˆ’åˆ†æå™¨

```python
#!/usr/bin/env python3
"""
Excel Verification Plan Analyzer
æ·±åº¦åˆ†æExceléªŒè¯è®¡åˆ’æ–‡æ¡£
"""

import pandas as pd
import json
import argparse
from pathlib import Path
import openpyxl
from datetime import datetime
import numpy as np

class ExcelVPlanAnalyzer:
    """ExceléªŒè¯è®¡åˆ’åˆ†æå™¨"""

    def __init__(self):
        self.required_columns = [
            'ID', 'Requirement Location', 'Feature', 'Sub-Feature',
            'Verification Goals', 'Pass/Fail Criteria', 'Coverage Method',
            'Priority', 'Owner', 'Target Date', 'Status', 'Comments'
        ]

    def analyze_structure(self, excel_file):
        """åˆ†æExcelæ–‡ä»¶ç»“æ„"""
        try:
            # è¯»å–Excelæ–‡ä»¶
            df = pd.read_excel(excel_file, sheet_name=0)

            # åŸºç¡€ç»“æ„åˆ†æ
            structure_analysis = {
                'total_rows': len(df),
                'total_columns': len(df.columns),
                'columns_present': list(df.columns),
                'missing_columns': [],
                'extra_columns': [],
                'empty_rows': 0,
                'duplicate_ids': 0
            }

            # æ£€æŸ¥å¿…éœ€åˆ—
            for col in self.required_columns:
                if col not in df.columns:
                    structure_analysis['missing_columns'].append(col)

            # æ£€æŸ¥é¢å¤–åˆ—
            for col in df.columns:
                if col not in self.required_columns:
                    structure_analysis['extra_columns'].append(col)

            # æ£€æŸ¥ç©ºè¡Œ
            structure_analysis['empty_rows'] = df.isnull().all(axis=1).sum()

            # æ£€æŸ¥é‡å¤ID
            if 'ID' in df.columns:
                structure_analysis['duplicate_ids'] = df['ID'].duplicated().sum()

            return structure_analysis

        except Exception as e:
            return {'error': f'Failed to analyze structure: {str(e)}'}

    def analyze_content_quality(self, excel_file):
        """åˆ†æå†…å®¹è´¨é‡"""
        df = pd.read_excel(excel_file, sheet_name=0)

        quality_analysis = {
            'completeness_score': 0,
            'field_analysis': {},
            'quality_issues': [],
            'recommendations': []
        }

        # åˆ†ææ¯ä¸ªå­—æ®µçš„å®Œæ•´æ€§
        for col in self.required_columns:
            if col in df.columns:
                non_null_count = df[col].notna().sum()
                total_count = len(df)
                completeness = (non_null_count / total_count) * 100

                quality_analysis['field_analysis'][col] = {
                    'completeness': completeness,
                    'missing_count': total_count - non_null_count,
                    'unique_values': df[col].nunique(),
                    'sample_values': df[col].dropna().head(3).tolist()
                }

                if completeness < 90:
                    quality_analysis['quality_issues'].append(
                        f'{col}å­—æ®µå®Œæ•´æ€§ä¸è¶³: {completeness:.1f}%'
                    )

        # è®¡ç®—æ€»ä½“å®Œæ•´æ€§å¾—åˆ†
        field_scores = [info['completeness'] for info in quality_analysis['field_analysis'].values()]
        quality_analysis['completeness_score'] = np.mean(field_scores) if field_scores else 0

        return quality_analysis

    def analyze_verification_goals(self, excel_file):
        """åˆ†æéªŒè¯ç›®æ ‡è´¨é‡"""
        df = pd.read_excel(excel_file, sheet_name=0)

        if 'Verification Goals' not in df.columns:
            return {'error': 'Verification Goals column not found'}

        goals_analysis = {
            'total_goals': 0,
            'clear_goals': 0,
            'vague_goals': 0,
            'goal_quality_score': 0,
            'common_issues': [],
            'examples': {
                'good_goals': [],
                'bad_goals': []
            }
        }

        # å®šä¹‰è´¨é‡æ ‡å‡†
        good_indicators = ['verify', 'check', 'validate', 'confirm', 'ensure']
        bad_indicators = ['test', 'make sure', 'works', 'functions properly']

        verification_goals = df['Verification Goals'].dropna()
        goals_analysis['total_goals'] = len(verification_goals)

        for goal in verification_goals:
            goal_str = str(goal).lower()

            # æ£€æŸ¥ç›®æ ‡æ˜ç¡®æ€§
            is_clear = any(indicator in goal_str for indicator in good_indicators)
            is_vague = any(indicator in goal_str for indicator in bad_indicators)

            if is_clear and not is_vague:
                goals_analysis['clear_goals'] += 1
                if len(goals_analysis['examples']['good_goals']) < 3:
                    goals_analysis['examples']['good_goals'].append(str(goal))
            elif is_vague:
                goals_analysis['vague_goals'] += 1
                if len(goals_analysis['examples']['bad_goals']) < 3:
                    goals_analysis['examples']['bad_goals'].append(str(goal))

        # è®¡ç®—ç›®æ ‡è´¨é‡å¾—åˆ†
        if goals_analysis['total_goals'] > 0:
            goals_analysis['goal_quality_score'] = (
                goals_analysis['clear_goals'] / goals_analysis['total_goals'] * 100
            )

        return goals_analysis

    def analyze_coverage_methods(self, excel_file):
        """åˆ†æè¦†ç›–ç‡æ–¹æ³•åˆ†å¸ƒ"""
        df = pd.read_excel(excel_file, sheet_name=0)

        if 'Coverage Method' not in df.columns:
            return {'error': 'Coverage Method column not found'}

        coverage_analysis = {
            'method_distribution': {},
            'coverage_completeness': 0,
            'method_quality': {}
        }

        coverage_methods = df['Coverage Method'].dropna()

        # ç»Ÿè®¡è¦†ç›–ç‡æ–¹æ³•åˆ†å¸ƒ
        method_keywords = {
            'Functional Coverage': ['functional coverage', 'covergroup', 'coverpoint'],
            'Code Coverage': ['code coverage', 'line coverage', 'branch coverage'],
            'Assertion Coverage': ['assertion', 'sva', 'property'],
            'Self-checking': ['self-checking', 'self checking'],
            'Reference Model': ['reference model', 'golden model', 'imperas']
        }

        for method_name, keywords in method_keywords.items():
            count = 0
            for coverage in coverage_methods:
                coverage_str = str(coverage).lower()
                if any(keyword in coverage_str for keyword in keywords):
                    count += 1

            coverage_analysis['method_distribution'][method_name] = {
                'count': count,
                'percentage': (count / len(coverage_methods) * 100) if coverage_methods.any() else 0
            }

        return coverage_analysis

    def generate_recommendations(self, analyses):
        """åŸºäºåˆ†æç»“æœç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []

        # ç»“æ„å»ºè®®
        structure = analyses.get('structure', {})
        if structure.get('missing_columns'):
            recommendations.append({
                'category': 'Structure',
                'priority': 'High',
                'issue': f"ç¼ºå°‘å¿…éœ€åˆ—: {', '.join(structure['missing_columns'])}",
                'recommendation': 'æ·»åŠ ç¼ºå°‘çš„åˆ—å¹¶å¡«å……ç›¸åº”å†…å®¹'
            })

        # å†…å®¹è´¨é‡å»ºè®®
        quality = analyses.get('content_quality', {})
        if quality.get('completeness_score', 0) < 90:
            recommendations.append({
                'category': 'Completeness',
                'priority': 'High',
                'issue': f"å†…å®¹å®Œæ•´æ€§ä¸è¶³: {quality['completeness_score']:.1f}%",
                'recommendation': 'å¡«å……ç¼ºå¤±çš„å­—æ®µå†…å®¹ï¼Œç›®æ ‡å®Œæ•´æ€§â‰¥95%'
            })

        # éªŒè¯ç›®æ ‡å»ºè®®
        goals = analyses.get('verification_goals', {})
        if goals.get('goal_quality_score', 0) < 80:
            recommendations.append({
                'category': 'Goal Quality',
                'priority': 'Medium',
                'issue': f"éªŒè¯ç›®æ ‡è´¨é‡éœ€è¦æ”¹è¿›: {goals['goal_quality_score']:.1f}%",
                'recommendation': 'ä½¿ç”¨æ›´æ˜ç¡®çš„éªŒè¯åŠ¨è¯ï¼Œé¿å…æ¨¡ç³Šè¡¨è¾¾'
            })

        return recommendations

    def generate_report(self, excel_file, output_format='json'):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        analyses = {}

        # æ‰§è¡Œå„ç§åˆ†æ
        analyses['structure'] = self.analyze_structure(excel_file)
        analyses['content_quality'] = self.analyze_content_quality(excel_file)
        analyses['verification_goals'] = self.analyze_verification_goals(excel_file)
        analyses['coverage_methods'] = self.analyze_coverage_methods(excel_file)

        # ç”Ÿæˆå»ºè®®
        recommendations = self.generate_recommendations(analyses)

        # æ„å»ºæœ€ç»ˆæŠ¥å‘Š
        report = {
            'file_info': {
                'filename': Path(excel_file).name,
                'analysis_timestamp': datetime.now().isoformat(),
                'file_size': Path(excel_file).stat().st_size
            },
            'analyses': analyses,
            'recommendations': recommendations,
            'overall_score': self.calculate_overall_score(analyses)
        }

        return report

    def calculate_overall_score(self, analyses):
        """è®¡ç®—æ€»ä½“è´¨é‡å¾—åˆ†"""
        scores = []

        # ç»“æ„å¾—åˆ†
        structure = analyses.get('structure', {})
        structure_score = 100
        if structure.get('missing_columns'):
            structure_score -= len(structure['missing_columns']) * 10
        if structure.get('empty_rows', 0) > 0:
            structure_score -= min(structure['empty_rows'] * 5, 20)
        scores.append(max(structure_score, 0))

        # å†…å®¹è´¨é‡å¾—åˆ†
        content_score = analyses.get('content_quality', {}).get('completeness_score', 0)
        scores.append(content_score)

        # éªŒè¯ç›®æ ‡å¾—åˆ†
        goals_score = analyses.get('verification_goals', {}).get('goal_quality_score', 0)
        scores.append(goals_score)

        return np.mean(scores) if scores else 0

def main():
    parser = argparse.ArgumentParser(description='Excel Verification Plan Analyzer')
    parser.add_argument('--input', required=True, help='Input Excel file')
    parser.add_argument('--output', help='Output report file')
    parser.add_argument('--format', choices=['json', 'html'], default='json',
                        help='Output format')

    args = parser.parse_args()

    analyzer = ExcelVPlanAnalyzer()
    report = analyzer.generate_report(args.input, args.format)

    if args.output:
        if args.format == 'json':
            with open(args.output, 'w') as f:
                json.dump(report, f, indent=2)
        elif args.format == 'html':
            # ç”ŸæˆHTMLæŠ¥å‘Šï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            html_content = generate_html_report(report)
            with open(args.output, 'w') as f:
                f.write(html_content)

    # è¾“å‡ºæ‘˜è¦
    print(f"ğŸ“Š éªŒè¯è®¡åˆ’åˆ†æå®Œæˆ")
    print(f"æ–‡ä»¶: {args.input}")
    print(f"æ€»ä½“å¾—åˆ†: {report['overall_score']:.1f}%")
    print(f"å»ºè®®æ•°é‡: {len(report['recommendations'])}")

def generate_html_report(report):
    """ç”ŸæˆHTMLæ ¼å¼æŠ¥å‘Š"""
    html = f"""
<!DOCTYPE html>
<html>
<head>
    <title>Verification Plan Analysis Report</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 40px; }}
        .score {{ font-size: 24px; font-weight: bold; color: #2196F3; }}
        .section {{ margin: 20px 0; padding: 15px; border-left: 4px solid #2196F3; }}
        .recommendation {{ margin: 10px 0; padding: 10px; background-color: #f5f5f5; }}
        .high-priority {{ border-left: 4px solid #f44336; }}
        .medium-priority {{ border-left: 4px solid #ff9800; }}
    </style>
</head>
<body>
    <h1>Verification Plan Analysis Report</h1>

    <div class="section">
        <h2>Overall Score</h2>
        <div class="score">{report['overall_score']:.1f}%</div>
    </div>

    <div class="section">
        <h2>File Information</h2>
        <p><strong>File:</strong> {report['file_info']['filename']}</p>
        <p><strong>Analysis Time:</strong> {report['file_info']['analysis_timestamp']}</p>
        <p><strong>File Size:</strong> {report['file_info']['file_size']} bytes</p>
    </div>

    <div class="section">
        <h2>Recommendations</h2>
        {''.join(f'''
        <div class="recommendation {rec['priority'].lower()}-priority">
            <strong>[{rec['priority']}] {rec['category']}</strong><br/>
            <strong>Issue:</strong> {rec['issue']}<br/>
            <strong>Recommendation:</strong> {rec['recommendation']}
        </div>
        ''' for rec in report['recommendations'])}
    </div>

    <div class="section">
        <h2>Detailed Analysis</h2>
        <pre>{json.dumps(report['analyses'], indent=2)}</pre>
    </div>
</body>
</html>
    """
    return html

if __name__ == "__main__":
    main()
```

### 2. requirements.txt

```
pandas>=1.3.0
openpyxl>=3.0.7
numpy>=1.21.0
matplotlib>=3.4.2
seaborn>=0.11.1
plotly>=5.0.0
jinja2>=3.0.0
requests>=2.25.1
pyyaml>=5.4.1
click>=8.0.0
rich>=10.0.0
```

### 3. å®Œæ•´æ€§æ£€æŸ¥å™¨

```python
#!/usr/bin/env python3
"""
Completeness Checker
éªŒè¯è®¡åˆ’å®Œæ•´æ€§å’Œéœ€æ±‚è¦†ç›–åº¦æ£€æŸ¥
"""

import json
import pandas as pd
import argparse
from pathlib import Path
from typing import Dict, List, Set
import re

class CompletenessChecker:
    """éªŒè¯è®¡åˆ’å®Œæ•´æ€§æ£€æŸ¥å™¨"""

    def __init__(self, requirements_db_file):
        """åˆå§‹åŒ–ï¼ŒåŠ è½½éœ€æ±‚æ•°æ®åº“"""
        with open(requirements_db_file, 'r') as f:
            self.requirements_db = json.load(f)

        self.all_requirements = set()
        self.requirement_categories = {}

        # æ„å»ºéœ€æ±‚ç´¢å¼•
        for category, reqs in self.requirements_db.items():
            self.requirement_categories[category] = set()
            for req in reqs:
                req_id = req['id']
                self.all_requirements.add(req_id)
                self.requirement_categories[category].add(req_id)

    def extract_requirements_from_vplan(self, excel_file) -> Set[str]:
        """ä»éªŒè¯è®¡åˆ’ä¸­æå–å·²è¦†ç›–çš„éœ€æ±‚"""
        df = pd.read_excel(excel_file, sheet_name=0)

        covered_requirements = set()

        if 'Requirement Location' in df.columns:
            for req_loc in df['Requirement Location'].dropna():
                # è§£æéœ€æ±‚ä½ç½®ï¼Œæå–éœ€æ±‚ID
                req_ids = self.parse_requirement_location(str(req_loc))
                covered_requirements.update(req_ids)

        return covered_requirements

    def parse_requirement_location(self, req_location: str) -> List[str]:
        """è§£æéœ€æ±‚ä½ç½®å­—ç¬¦ä¸²ï¼Œæå–éœ€æ±‚ID"""
        # ç®€åŒ–çš„è§£æé€»è¾‘ï¼Œå®é™…å¯èƒ½æ›´å¤æ‚
        req_ids = []

        # åŒ¹é…æ¨¡å¼å¦‚ "RISC-V ISA Spec 2.4.1"
        patterns = [
            r'RISC-V ISA Spec (\d+\.\d+\.?\d*)',
            r'CV32E40P Manual (\d+\.\d+\.?\d*)',
            r'RISC-V Priv Spec (\d+\.\d+\.?\d*)',
        ]

        for pattern in patterns:
            matches = re.findall(pattern, req_location)
            req_ids.extend(matches)

        return req_ids

    def check_completeness(self, vplan_files: List[str]) -> Dict:
        """æ£€æŸ¥éªŒè¯è®¡åˆ’å®Œæ•´æ€§"""
        all_covered_requirements = set()

        # æ”¶é›†æ‰€æœ‰éªŒè¯è®¡åˆ’è¦†ç›–çš„éœ€æ±‚
        for vplan_file in vplan_files:
            covered = self.extract_requirements_from_vplan(vplan_file)
            all_covered_requirements.update(covered)

        # åˆ†æå®Œæ•´æ€§
        missing_requirements = self.all_requirements - all_covered_requirements
        extra_requirements = all_covered_requirements - self.all_requirements

        # åˆ†ç±»åˆ†æ
        category_analysis = {}
        for category, category_reqs in self.requirement_categories.items():
            covered_in_category = all_covered_requirements & category_reqs
            missing_in_category = category_reqs - covered_in_category

            category_analysis[category] = {
                'total': len(category_reqs),
                'covered': len(covered_in_category),
                'missing': len(missing_in_category),
                'coverage_rate': len(covered_in_category) / len(category_reqs) * 100,
                'missing_list': list(missing_in_category)
            }

        # æ€»ä½“åˆ†æ
        total_coverage_rate = (
            len(all_covered_requirements & self.all_requirements) /
            len(self.all_requirements) * 100
        ) if self.all_requirements else 100

        return {
            'summary': {
                'total_requirements': len(self.all_requirements),
                'covered_requirements': len(all_covered_requirements & self.all_requirements),
                'missing_requirements': len(missing_requirements),
                'extra_requirements': len(extra_requirements),
                'coverage_rate': total_coverage_rate
            },
            'category_analysis': category_analysis,
            'missing_requirements': list(missing_requirements),
            'extra_requirements': list(extra_requirements),
            'vplan_analysis': {
                'files_analyzed': vplan_files,
                'requirements_per_file': [
                    {
                        'file': vplan_file,
                        'requirements': len(self.extract_requirements_from_vplan(vplan_file))
                    }
                    for vplan_file in vplan_files
                ]
            }
        }

def main():
    parser = argparse.ArgumentParser(description='Verification Plan Completeness Checker')
    parser.add_argument('--requirements', required=True,
                        help='Requirements database JSON file')
    parser.add_argument('--plans-dir', help='Directory containing verification plans')
    parser.add_argument('--plan-files', nargs='+',
                        help='Specific verification plan files')
    parser.add_argument('--output', help='Output report file')

    args = parser.parse_args()

    # ç¡®å®šè¦åˆ†æçš„æ–‡ä»¶
    vplan_files = []
    if args.plans_dir:
        vplan_files.extend(Path(args.plans_dir).glob('**/*.xlsx'))
    if args.plan_files:
        vplan_files.extend(args.plan_files)

    vplan_files = [str(f) for f in vplan_files]

    if not vplan_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°è¦åˆ†æçš„éªŒè¯è®¡åˆ’æ–‡ä»¶")
        return

    # æ‰§è¡Œå®Œæ•´æ€§æ£€æŸ¥
    checker = CompletenessChecker(args.requirements)
    results = checker.check_completeness(vplan_files)

    # è¾“å‡ºç»“æœ
    if args.output:
        with open(args.output, 'w') as f:
            json.dump(results, f, indent=2)

    # æ‰“å°æ‘˜è¦
    summary = results['summary']
    print(f"ğŸ“Š éªŒè¯è®¡åˆ’å®Œæ•´æ€§æ£€æŸ¥ç»“æœ")
    print(f"éœ€æ±‚è¦†ç›–ç‡: {summary['coverage_rate']:.1f}%")
    print(f"å·²è¦†ç›–éœ€æ±‚: {summary['covered_requirements']}/{summary['total_requirements']}")
    print(f"ç¼ºå¤±éœ€æ±‚: {summary['missing_requirements']}")

    # åˆ†ç±»è¯¦æƒ…
    print(f"\nğŸ“‹ åˆ†ç±»è¦†ç›–è¯¦æƒ…:")
    for category, analysis in results['category_analysis'].items():
        print(f"  {category}: {analysis['coverage_rate']:.1f}% "
              f"({analysis['covered']}/{analysis['total']})")

if __name__ == "__main__":
    main()
```

## ğŸ“ˆ ä½¿ç”¨æ•ˆæœå’Œæœ€ä½³å®è·µ

### ä½¿ç”¨æ•ˆæœæ•°æ®

åŸºäºCV32E40Pé¡¹ç›®ä½¿ç”¨è¿™äº›å·¥å…·çš„å®é™…æ•ˆæœï¼š

| å·¥å…· | ä½¿ç”¨å‰ | ä½¿ç”¨å | æ”¹è¿›å¹…åº¦ |
|------|--------|--------|----------|
| **Excelåˆ†æå™¨** | 4å°æ—¶æ‰‹å·¥æ£€æŸ¥ | 5åˆ†é’Ÿè‡ªåŠ¨åˆ†æ | -95% æ—¶é—´ |
| **å®Œæ•´æ€§æ£€æŸ¥** | 70%éœ€æ±‚è¦†ç›–å‘ç°ç‡ | 98%éœ€æ±‚è¦†ç›–å‘ç°ç‡ | +40% å‡†ç¡®æ€§ |
| **è´¨é‡è¯„åˆ†** | ä¸»è§‚è¯„ä¼° | å®¢è§‚é‡åŒ–è¯„åˆ† | 100% å®¢è§‚åŒ– |
| **ä»ªè¡¨æ¿ç”Ÿæˆ** | å‘¨æŠ¥æ‰‹å·¥åˆ¶ä½œ | å®æ—¶è‡ªåŠ¨æ›´æ–° | å®æ—¶åŒ– |

### æœ€ä½³å®è·µå»ºè®®

1. **å·¥å…·é›†æˆåŒ–ä½¿ç”¨**
   ```bash
   # å»ºè®®çš„å·¥å…·ä½¿ç”¨æµç¨‹
   python3 tools/excel_analyzer.py --input vplan.xlsx --output analysis.json
   python3 tools/completeness_checker.py --requirements reqs.json --plan-files vplan.xlsx
   python3 tools/dashboard_generator.py --data analysis.json --output dashboard.html
   ```

2. **è‡ªåŠ¨åŒ–é›†æˆ**
   - é›†æˆåˆ°CI/CD pipeline
   - å®šæ—¶æ‰§è¡Œåˆ†æä»»åŠ¡
   - è‡ªåŠ¨ç”Ÿæˆå’Œåˆ†å‘æŠ¥å‘Š

3. **å®šåˆ¶åŒ–é…ç½®**
   - æ ¹æ®é¡¹ç›®éœ€æ±‚è°ƒæ•´åˆ†æå‚æ•°
   - é…ç½®é¡¹ç›®ç‰¹å®šçš„è´¨é‡æ ‡å‡†
   - å®šåˆ¶æŠ¥å‘Šæ¨¡æ¿å’Œæ ¼å¼

---

**é‡è¦æç¤º**ï¼šè¿™äº›å·¥å…·åŸºäºCV32E40Pé¡¹ç›®çš„å®é™…éœ€æ±‚å¼€å‘ï¼Œå·²åœ¨ç”Ÿäº§ç¯å¢ƒä¸­éªŒè¯æœ‰æ•ˆã€‚å»ºè®®æ ¹æ®å…·ä½“é¡¹ç›®éœ€æ±‚è¿›è¡Œé€‚å½“çš„é…ç½®å’Œå®šåˆ¶åŒ–ã€‚